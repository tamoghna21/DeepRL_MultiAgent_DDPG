{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Reinforcement learning - Training an Agent to Solve Unity-ML Tennis environment using MultiAgent DDPG algorithm\n",
    "---\n",
    "\n",
    "This notebook presents the code to train a Deep RL Agent to solve the Unity ML-Agent Tennis environment. The training uses Multi Agent Deep Deterministic Policy Gradient algorithm.\n",
    "\n",
    "### 1. Import the packages and Start the Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from deep_rl.agent.DDPG_agent import DDPGAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "# Tennis environment. In this environment, two agents control rackets to bounce a ball over a net.\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\") #In mac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n",
      "8\n",
      "24\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])\n",
    "\n",
    "print(brain.vector_observation_space_size)\n",
    "print(state_size)\n",
    "print(brain.vector_action_space_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new agent\n",
    "agent = DDPGAgent(state_size=state_size, action_size=brain.vector_action_space_size, random_seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "#Just for debug/display purpose\n",
    "print(state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.62329803 -1.78604795]\n",
      " [-0.03083499  1.22016808]]\n"
     ]
    }
   ],
   "source": [
    "#Just for debug/display purpose\n",
    "actions = np.random.randn(num_agents, action_size)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.         -7.38993645 -1.5\n",
      "  -0.          0.          6.83172083  5.99607611 -0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.         -6.70024681 -1.5\n",
      "   0.          0.         -6.83172083  5.99607611  0.          0.        ]]\n",
      "(2, 24)\n",
      "[[ 0.03440508 -0.00063448]\n",
      " [ 0.04507908 -0.01415111]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamoghnadas/opt/anaconda3/envs/drlnd/lib/python3.6/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "#Just for debug/display purpose\n",
    "noise_factor = 0.1\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "states = env_info.vector_observations\n",
    "print(states)\n",
    "print(states.shape)\n",
    "actions = agent.act(states, noise_factor=noise_factor)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAvg Score: 0.02\tavg max score over the last 10 episodes: 0.01\n",
      "Episode 200\tAvg Score: 0.01\tavg max score over the last 10 episodes: 0.00\n",
      "Episode 300\tAvg Score: 0.02\tavg max score over the last 10 episodes: 0.02\n",
      "Episode 400\tAvg Score: 0.05\tavg max score over the last 10 episodes: 0.09\n",
      "Episode 500\tAvg Score: 0.06\tavg max score over the last 10 episodes: 0.02\n",
      "Episode 600\tAvg Score: 0.06\tavg max score over the last 10 episodes: 0.09\n",
      "Episode 700\tAvg Score: 0.10\tavg max score over the last 10 episodes: 0.11\n",
      "Episode 800\tAvg Score: 0.16\tavg max score over the last 10 episodes: 0.11\n",
      "Episode 900\tAvg Score: 0.31\tavg max score over the last 10 episodes: 1.31\n",
      "Episode 917\tmax score: 2.60\tavg max score over the last 10 episodes: 1.66\n",
      "Environment solved in 817 episodes!\tAverage Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "def train_maddpg(n_episodes=3000, max_t=10000, print_every=100):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    noise_factor = 0.1  # A factor to multiply random noise\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations # states.shape is (2,24). env_reset returned state of both tennis players\n",
    "        scores_agents = np.zeros(2)  # the scores of both tennis agents after an episode\n",
    "        agent.reset()\n",
    "        for t in range(max_t):\n",
    "            \n",
    "            # The Agent selects Actions\n",
    "            # actions for both the agents (both tennis players)\n",
    "            if i_episode < 100:\n",
    "                actions = np.random.randn(num_agents, action_size)  # use random actions for the first 100 episodes\n",
    "            else:\n",
    "                actions = agent.act(states, noise_factor=noise_factor)\n",
    "            \n",
    "            # Actions of the other player\n",
    "            actions_other_player = np.flip(actions, 0)\n",
    "            \n",
    "            # Environment processes the Action; produces new State, Rewards\n",
    "            env_info = env.step(actions)[brain_name]      \n",
    "            rewards = env_info.rewards                    \n",
    "            next_states = env_info.vector_observations\n",
    "            next_states_other_player = np.flip(next_states, 0)\n",
    "            dones = env_info.local_done \n",
    "            \n",
    "            # The Agent learns\n",
    "            #agent.step(states, actions, rewards, next_states, dones)\n",
    "            agent.step(states, actions, actions_other_player, rewards, next_states, next_states_other_player, dones) \n",
    "            \n",
    "            states = next_states\n",
    "            scores_agents += rewards\n",
    "            if np.any(dones):\n",
    "                break \n",
    "        avg_score = np.mean(scores_agents)  # the average score of the agents\n",
    "        max_score = np.max(scores_agents)  # the max score of the agents\n",
    "        #scores_deque.append(avg_score)\n",
    "        scores_deque.append(max_score)\n",
    "        #scores.append(avg_score)\n",
    "        scores.append(max_score)\n",
    "        \n",
    "        #noise reduced during training as episodes progresses\n",
    "        noise_factor = max(0.995 * noise_factor, 0.01)\n",
    "        \n",
    "        #print('\\rEpisode {:d}\\tscore: {:.2f}\\taverage score over the last 10 episodes: {:.2f}'.format(i_episode, scores_deque[-1], np.mean(list(scores_deque)[-10:])), end=\"\")\n",
    "        print('\\rEpisode {:d}\\tmax score: {:.2f}\\tavg max score over the last 10 episodes: {:.2f}'.format(i_episode, scores_deque[-1], np.mean(list(scores_deque)[-10:])), end=\"\")\n",
    "        #if i_episode % 10 == 0:\n",
    "            #torch.save(agent.actor_local.state_dict(), 'weights/checkpoint_actor_{:d}_{:.2f}.pth'.format(i_episode, scores_deque[-1]))\n",
    "            #torch.save(agent.critic_local.state_dict(), 'weights/checkpoint_critic_{:d}_{:.2f}.pth'.format(i_episode, scores_deque[-1]))\n",
    "        if i_episode > 100 and np.mean(scores_deque) > 0.5:\n",
    "            torch.save(agent.actor_local.state_dict(), 'weights/checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'weights/checkpoint_critic.pth')\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_deque)))\n",
    "            break\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAvg Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            \n",
    "    return scores\n",
    "\n",
    "scores = train_maddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot Score vs Episode#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
